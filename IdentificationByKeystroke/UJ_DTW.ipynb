{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.svm import libsvm\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtw_matrix1 = np.load(\"dtw_matrix1.npy\")\n",
    "dtw_matrix2 = np.load(\"dtw_matrix2.npy\")\n",
    "test_index = np.load(\"test_index.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_in = open(\"C:/Users/valikund/Desktop/Challange/keystrokes-12users-train-labels.txt\",\"r\")\n",
    "test_in = open(\"C:/Users/valikund/Desktop/Challange/keystrokes-12users-test-hypothetic-labels.txt\",\"r\")\n",
    "train_x1,train_x2, train_y = [],[],[]\n",
    "test_index,test_x1,test_x2,test_y = [],[],[],[]\n",
    "row = training_in.readline().strip()\n",
    "while row:\n",
    "    row = row.split(',')\n",
    "    train_x1.append(dtw_matrix1[int(row[0])-1])\n",
    "    train_x2.append(dtw_matrix2[int(row[0])-1])\n",
    "    train_y.append(int(row[1]))\n",
    "    row = training_in.readline()\n",
    "training_in.close()\n",
    "#the test datasets\n",
    "row = test_in.readline().strip()\n",
    "while row:\n",
    "    row = row.split(',')\n",
    "    test_x1.append(dtw_matrix1[int(row[0])-1])\n",
    "    test_x2.append(dtw_matrix2[int(row[0])-1])\n",
    "    test_index.append(int(row[0]))\n",
    "    test_y.append(int(row[1]))\n",
    "    row = test_in.readline()\n",
    "test_in.close()\n",
    "#sorting the values\n",
    "train_x_sorted1 = []\n",
    "train_x_sorted2 = []\n",
    "train_y_arranged = np.array(train_y)\n",
    "sort_index = np.argsort(train_y_arranged)\n",
    "for position in sort_index:\n",
    "    train_x_sorted1.append(train_x1[position])\n",
    "    train_x_sorted2.append(train_x2[position])\n",
    "train_x1 = train_x_sorted1\n",
    "train_x2 = train_x_sorted2\n",
    "train_y.sort() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40021.0\n"
     ]
    }
   ],
   "source": [
    "train_x1 = np.array(train_x1)\n",
    "train_x2 = np.array(train_x2)\n",
    "test_x1 = np.array(test_x1)\n",
    "test_x2 = np.array(test_x2)\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "print(train_x2[58][58])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16598360655737704"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_x,train_y)\n",
    "pred = knn.predict(test_x)\n",
    "accuracy_score(pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31967213114754101"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1500)\n",
    "rf.fit(train_x1,train_y)\n",
    "pred = rf.predict(test_x1)\n",
    "accuracy_score(pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24590163934426229"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LogisticRegressionCV()\n",
    "lr2.fit(train_x2,train_y)\n",
    "pred2 = lr2.predict(test_x2)\n",
    "accuracy_score(pred2, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = np.hstack((train_x1,train_x2))\n",
    "test_x = np.hstack((test_x1,test_x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28278688524590162"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1500)\n",
    "rf.fit(train_x,train_y)\n",
    "pred = rf.predict(test_x)\n",
    "accuracy_score(pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28073770491803279"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegressionCV()\n",
    "lr.fit(train_x, train_y)\n",
    "pred = lr.predict(test_x)\n",
    "accuracy_score(pred,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc1 = StandardScaler()\n",
    "train_x1_std =sc1.fit_transform(train_x1)\n",
    "test_x1_std = sc1.transform(test_x1)\n",
    "sc2 = StandardScaler()\n",
    "train_x2_std =sc2.fit_transform(train_x2)\n",
    "test_x2_std = sc2.transform(test_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25614754098360654"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LogisticRegression(C = 100)\n",
    "lr2.fit(train_x2_std,train_y)\n",
    "pred2 = lr2.predict(test_x2_std)\n",
    "accuracy_score(pred2, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34426229508196721"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1 = LogisticRegressionCV()\n",
    "lr1.fit(train_x1,train_y)\n",
    "pred = lr1.predict(test_x1)\n",
    "accuracy_score(pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "semi1 = []\n",
    "semi2 = []\n",
    "semi_y = []\n",
    "for index,y in enumerate(test_y):\n",
    "        if y==pred[index]:\n",
    "            semi1.append(test_x1[index])\n",
    "            semi2.append(test_x2[index])\n",
    "            semi_y.append(y)\n",
    "concat_x1 = np.vstack((train_x1,np.array(semi1)))\n",
    "concat_x2 = np.vstack((train_x2,np.array(semi2)))\n",
    "concat_y = np.hstack((train_y,np.array(semi_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42008196721311475"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1 = LogisticRegressionCV()\n",
    "lr1.fit(concat_x1,concat_y)\n",
    "predd = lr1.predict(test_x1)\n",
    "accuracy_score(predd, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "semi1 = []\n",
    "semi2 = []\n",
    "semi_y = []\n",
    "for index,y in enumerate(test_y):\n",
    "        if y==pred[index]:\n",
    "            semi1.append(test_x1[index])\n",
    "            semi2.append(test_x2[index])\n",
    "            semi_y.append(y)\n",
    "concat_x1 = np.vstack((train_x1,np.array(semi1)))\n",
    "concat_x2 = np.vstack((train_x2,np.array(semi2)))\n",
    "concat_y = np.hstack((train_y,np.array(semi_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = open(\"submission.txt\",\"w\")\n",
    "numb = 0\n",
    "for index,y in enumerate(test_y):\n",
    "        if y==predd[index]:\n",
    "            result = 1 \n",
    "            numb = numb + 1\n",
    "        else:\n",
    "            result = 0\n",
    "        out.write(str(test_index[index])+\",\")\n",
    "        out.write(str(result))\n",
    "        out.write(\"\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3892.0 29487.0\n"
     ]
    }
   ],
   "source": [
    "print(train_x1[32][30],train_x2[32][30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
